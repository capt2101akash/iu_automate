# Ansible playbook to establish passwordless SSH login to remote hosts.
#
# https://github.com/ilias-sp/ansible-setup-passwordless-ssh
#
# 
# fill in your environment information in the hosts file:
# 
# ssh_key_filename: the filename of the SSH key to be generated
# remote_machine_username: the username of the remote host that you want to login as
# remote_machine_password: the password of that user on the remote host. Assuming you are attempting to run this to multiple hosts, the users exists to all machines and have the same password
# [ansible_setup_passwordless_setup_group]: add the list of remote hosts you want to enable the passwordless login.
# 
# 
# 
# run the playbook as:
#
# ansible-playbook -i hosts ansible_setup_passwordless_ssh.yml
#
#
# 
---
- hosts: local_host
  gather_facts: false
  vars_prompt:
    - name: confirmation
      prompt: "Type 'YES' to establish passwordless login to the remote hosts:"
      default: 'NO'
      private: no
      when: confirmation != "YES"

    - name: password
      prompt: "Enter Remote user password"
      private: yes

    - name: username_github
      prompt: "Enter username"

    - name: password_github
      prompt: "Enter password"

  pre_tasks:
    - name: "Check Confirmation"
      fail: msg="Exiting... You must type 'YES' to continue."
      when: confirmation != "YES"

  tasks:
    - name: check .ssh local directory exists
      stat:
        path: "~/.ssh"
      register: ssh_directory_exists_check

    # - debug:
    #     var: ssh_directory_exists_check

    - name: create ~/.ssh local directory
      file:
        path: "~/.ssh"
        state: directory
        mode: "0700"
      register: ssh_directory_creation
      when: ssh_directory_exists_check is defined and ssh_directory_exists_check.stat.exists == false

    # - debug:
    #     var: ssh_directory_creation

    - name: check .ssh key file exists
      stat:
        path: "~/.ssh/{{item}}"
      register: ssh_key_file_exists_check
      with_items:
        - "{{ssh_key_filename}}"
        - "{{ssh_key_filename}}.pub"

    # - debug:
    #     var: ssh_key_file_exists_check.results[1].stat.exists

    - name: generate ssh key on local machine
      shell: "ssh-keygen -t rsa -f ~/.ssh/{{ssh_key_filename}} -P \"\""
      register: ssh_key_creation
      failed_when: ssh_key_creation.rc != 0
      when: ssh_key_file_exists_check is defined and ssh_key_file_exists_check.results[0].stat.exists == false and ssh_key_file_exists_check.results[1].stat.exists == false

    # - debug:
    #     var: ssh_key_creation

    - name: check .ssh/config file exists
      stat:
        path: "~/.ssh/config"
      register: ssh_config_file_exists_check

    # - debug:
    #     var: ssh_config_file_exists_check

    - name: create the ~/.ssh/config file
      file:
        path: "~/.ssh/config"
        state: touch
        mode: "0644"
      register: ssh_config_file_creation
      when: ssh_config_file_exists_check is defined and ssh_config_file_exists_check.stat.exists == false

    - name: add the new ssh key to the ~/.ssh/config file
      lineinfile:
        path: "~/.ssh/config"
        line: "IdentityFile ~/.ssh/{{ssh_key_filename}}"
        state: present
        backup: yes
      register: ssh_config_file_key_addition
    
    - name: install sshpass
      shell: apt install -y sshpass
    # - debug:
    #     var: ssh_config_file_key_addition

    - name: distribute the ssh key to the remote hosts
      shell: "sshpass -p \"{{password}}\" ssh-copy-id -o StrictHostKeyChecking=no -i ~/.ssh/{{ssh_key_filename}}.pub {{remote_machine_username}}@{{item}}"
      register: ssh_copy_id_execution
      with_items: 
        - "{{ groups['k8s_worker_nodes']}}"
        - "{{ groups['k8s_master_nodes']}}"
      failed_when: ssh_copy_id_execution.rc != 0

    # - debug:
    #     var: ssh_copy_id_execution

- hosts: local_host
  gather_facts: false
  tasks:

    - name: check ssh to remote hosts works
      shell: "hostname; id"
      register: ssh_connection_test
      #failed_when: ssh_connection_test.rc != 0

    - debug:
        var: ssh_connection_test.stdout_lines

    - name: update repo
      shell: apt update -y
    
    - name: install python
      shell: apt install python

    - name: install firewall
      shell: apt install -y firewalld
      ignore_errors: True

    - name: disable firewalld
      shell: service firewalld stop

    - name: install selinux-utils
      shell: apt install -y selinux-utils

    - name: disable selinux-utils
      shell: setenforce 0
      ignore_errors: True

    - name: install git
      shell: apt install -y git

    - name: install python-pip
      shell: apt install -y python-pip

    - name: install python3-pip
      shell: apt install -y python3-pip

    - name: install jinja2
      shell: pip install jinja2

    - name: install python3
      shell: apt install -y python3

    - name: install virtualenv
      shell: apt install -y virtualenv

    - name: Create virtualenv and use it
      shell: |
        virtualenv -p python3 k8s-cluster
        source k8s-cluster/bin/activate
      args:
        executable: /bin/bash

- hosts: local_host
  gather_facts: false
  tasks:

    - name: cloning kubespray
      shell: |
        git clone https://{{username_github}}:{{password_github}}@github.com/springml/iu_kubernetes.git 2> /dev/null || (cd iu_kubernetes/; git pull)
        cd iu_kubernetes/

    - name: install requirements of kubespray
      shell: pip3 install -r kubespray/requirements.txt

    - name: Deploy cluster
      shell: "ansible-playbook -i ./kubespray/inventory/testCluster/hosts.ini ./kubespray/cluster.yml -T 32"

    - name: Create .kube directory
      shell: "mkdir -p .kube/"

    - name: Copy kube config file 
      shell: "sudo scp {{remote_machine_username}}@{{item}}:/etc/kubernetes/admin.conf .kube/config"

    - name: Install kubectl 
      shell: |
        sudo apt-get update && sudo apt-get install -y apt-transport-https"
        curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -"
        echo "deb http://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee -a /etc/apt/sources.list.d/kubernetes.list
        sudo apt-get update
        sudo apt-get install -y kubectl

    - name: Install helm and tiller
      shell: |
        curl https://raw.githubusercontent.com/helm/helm/master/scripts/get > get_helm.sh
        chmod 700 get_helm.sh
        ./get_helm.sh
        kubectl create serviceaccount --namespace kube-system tiller
        kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller
        helm init --service-account tiller
